{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from vllm import LLM, SamplingParams\n",
    "# from vllm.assets.image import ImageAsset\n",
    "# from vllm.assets.video import VideoAsset\n",
    "# from vllm.utils import FlexibleArgumentParser\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# Modify OpenAI's API key and API base to use vLLM's API server.\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:8000/v1\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "\n",
    "\n",
    "models = client.models.list()\n",
    "model_path = models.data[0].id\n",
    "print(f'model_path: {model_path}')\n",
    "# model_path = \"/DATA/disk1/ceyao/models/Qwen/Qwen2.5-VL-7B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "\n",
    "def encode_base64_content_from_url(content_url: str) -> str:\n",
    "    \"\"\"Encode a content retrieved from a remote url to base64 format.\"\"\"\n",
    "\n",
    "    with requests.get(content_url) as response:\n",
    "        response.raise_for_status()\n",
    "        result = base64.b64encode(response.content).decode('utf-8')\n",
    "\n",
    "    return result\n",
    "\n",
    "from utils import encode_image_to_base64, decode_base64_to_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from contextlib import contextmanager\n",
    "from datetime import datetime\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    start = datetime.now()\n",
    "    yield\n",
    "    end = datetime.now()\n",
    "    print(f\"{name} 执行时间: {(end - start).total_seconds():.2f} 秒\")\n",
    "\n",
    "\n",
    "from vis_bbox import plot_bounding_boxes, parse_json, reshape_img\n",
    "from IPython.display import display\n",
    "import ast\n",
    "import json\n",
    "from json_repair import repair_json\n",
    "import json_repair\n",
    "\n",
    "def inference(prompt, img_url=None, system_prompt=\"You are a helpful assistant\", max_new_tokens=2048):\n",
    "    \n",
    "    image = Image.open(img_url)\n",
    "    w, h = image.size\n",
    "\n",
    "    img_base64 = encode_image_to_base64(image)\n",
    "\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        model=model_path,\n",
    "        max_completion_tokens=max_new_tokens,\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    # \"text\": \"What's in this image?\"\n",
    "                    \"text\": prompt\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        # \"url\": \"https://q9.itc.cn/images01/20240529/091866645b3c485fb1a493ecbe302e06.png\"\n",
    "                        \"url\": \"https://pics4.baidu.com/feed/b999a9014c086e06cff1723bb02d58fb0ad1cb1e.jpeg\"\n",
    "                        # \"url\": f\"data:image/jpeg;base64,{image_base64}\"\n",
    "                        # \"url\": f\"data:image/png;base64,{img_base64}\"\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }],\n",
    "    )\n",
    "    \n",
    "    # b = decode_base64_to_image(a1)\n",
    "    # plt.figure(1, figsize=(10,10))\n",
    "    # plt.axis('off')\n",
    "    # plt.imshow(b)\n",
    "    # plt.show()\n",
    "    prompt_tokens = chat_completion.usage.prompt_tokens\n",
    "    completion_tokens = chat_completion.usage.completion_tokens\n",
    "    total_tokens = chat_completion.usage.total_tokens\n",
    "\n",
    "    print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "    print(f\"Completion tokens: {completion_tokens}\")\n",
    "    print(f\"Total tokens: {total_tokens}\")\n",
    "\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    print(\"Output:\", response)\n",
    "\n",
    "    return response, h, w\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
    "\n",
    "# image_path = '/home/ceyao/Projects/DexGraspVLA-planner/planner-test/Gfp-wisconsin-madison-the-nature-boardwalk.jpg'\n",
    "# image_path = '/home/ceyao/Projects/DexGraspVLA-planner/planner-test/002_The_lion_king_Snyggve_in_the_Serengeti_National_Park_Photo_by_Giles_Laurent.jpg'\n",
    "image_path = '/home/ceyao/Projects/DexGraspVLA-planner/planner-test/2015_Kaczka_krzyżowka_w_wodzie_(samiec).jpg'\n",
    "# image_path = '/home/ceyao/Projects/DexGraspVLA-planner/planner-test/white/2_Color.png'\n",
    "# image_path = '/home/ceyao/Projects/DexGraspVLA-planner/planner-test/mid.png'\n",
    "# image_path = '/home/ceyao/Projects/DexGraspVLA-planner/planner-test/high.png'\n",
    "\n",
    "\n",
    "\n",
    "# image_path = reshape_img(image_path)\n",
    "\n",
    "# image_base64 = encode_base64_content_from_url(image_url)\n",
    "# image_path = '/home/ceyao/Projects/DexGraspVLA-planner/planner-test/low_quality_image.jpg'\n",
    "from PIL import Image\n",
    "\n",
    "img = Image.open(image_path)\n",
    "img\n",
    "# img.save('low_quality_image.jpg', quality=30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# prompt = \"框出桌面上所有的绿色物品的位置，并输出其坐标。\"\n",
    "# prompt = \"请以JSON格式输出图中所有绿色物品bbox的的坐标以及它们的名字和描述（例如红色盖子的瓶子，蓝色的玩偶），然后基于检测结果回答以下问题：图中物体的数目是多少？\"\n",
    "# prompt = \"请以JSON格式输出图中所有包含绿色区域物品的bbox的坐标以及它们的名字和描述（例如红色盖子的瓶子，蓝色的玩偶）\"\n",
    "# prompt = \"请以JSON格式输出图中所有物品的bbox的坐标以及它们的名字和描述（例如红色盖子的瓶子，蓝色的玩偶）\"\n",
    "# prompt = \"请以JSON格式输出图中（除了左边白色塑料盒以外的）所有物品的bbox的坐标以及它们的名字和描述（例如红色盖子的瓶子，蓝色的玩偶）\"\n",
    "# prompt = \"框出桌面上（不包括桌面下方以及凹陷处）所有的绿色物品的位置，并输出其坐标。\"\n",
    "prompt = \"描述图片\"\n",
    "\n",
    "with timer(\"API 请求\"):\n",
    "    response, input_height, input_width = inference(prompt, image_path)\n",
    "\n",
    "\n",
    "# # Parsing out the markdown fencing\n",
    "# bounding_boxes = parse_json(response)\n",
    "# try:\n",
    "#     json_output = ast.literal_eval(bounding_boxes)\n",
    "# except Exception as e:\n",
    "#     # print(f\"JSON 格式错误: {e}\")\n",
    "#     # end_idx = bounding_boxes.rfind('\"}') + len('\"}')\n",
    "#     # truncated_text = bounding_boxes[:end_idx] + \"]\"\n",
    "#     # json_output = ast.literal_eval(truncated_text)\n",
    "#     # fixed_boxes = bounding_boxes.replace('\"label: \"', '\"label\": \"')\n",
    "#     # bounding_boxes = repair_json(bounding_boxes, ensure_ascii=False)\n",
    "#     # json_output = json.loads(bounding_boxes)\n",
    "#     json_output = json_repair.loads(bounding_boxes)\n",
    "\n",
    "# print(\"\\n\\njson output:\\n\", json_output)\n",
    "\n",
    "# # plot_bounding_boxes(image, response, input_width, input_height)\n",
    "# # # 获取处理后的图像并显示\n",
    "# result_img = plot_bounding_boxes(Image.open(image_path), json_output, input_width, input_height)\n",
    "# new_img_path = image_path[:-4]+\"_25-72B_bbox.png\"\n",
    "# result_img.save(new_img_path)\n",
    "\n",
    "# display(result_img)  # Jupyter 会自动显示图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "a = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_path: deepseek-v3\n",
      "deepseek-v3\n",
      "deepseek-r1-distill-llama-70b\n",
      "deepseek-r1-distill-qwen-32b\n",
      "deepseek-r1-distill-qwen-14b\n",
      "deepseek-r1-distill-llama-8b\n",
      "deepseek-r1-distill-qwen-1.5b\n",
      "deepseek-r1-distill-qwen-7b\n",
      "deepseek-r1\n",
      "qwen1.5-7b-chat\n",
      "qwen-vl-ocr-latest\n",
      "qwen-vl-ocr\n",
      "qwen-coder-plus-1106\n",
      "qwen-coder-plus\n",
      "qwen-coder-plus-latest\n",
      "qwen2.5-coder-3b-instruct\n",
      "qwen2.5-coder-0.5b-instruct\n",
      "qwen2.5-coder-14b-instruct\n",
      "qwen2.5-coder-32b-instruct\n",
      "qwen-coder-turbo-0919\n",
      "qwen2.5-0.5b-instruct\n",
      "qwen2.5-1.5b-instruct\n",
      "qwen2.5-3b-instruct\n",
      "qwen2.5-7b-instruct\n",
      "qwen2.5-14b-instruct\n",
      "qwen2.5-32b-instruct\n",
      "qwen2.5-72b-instruct\n",
      "qwen2.5-coder-7b-instruct\n",
      "qwen2.5-math-1.5b-instruct\n",
      "qwen2.5-math-7b-instruct\n",
      "qwen2.5-math-72b-instruct\n",
      "qwen-turbo-0919\n",
      "qwen-turbo-latest\n",
      "qwen-plus-0919\n",
      "qwen-plus-latest\n",
      "qwen-max-0919\n",
      "qwen-max-latest\n",
      "qwen-coder-turbo\n",
      "qwen-coder-turbo-latest\n",
      "qwen-math-turbo-0919\n",
      "qwen-math-turbo\n",
      "qwen-math-turbo-latest\n",
      "qwen-math-plus-0919\n",
      "qwen-math-plus\n",
      "qwen-math-plus-latest\n",
      "qwen2-1.5b-instruct\n",
      "qwen2-57b-a14b-instruct\n",
      "qwen2-72b-instruct\n",
      "qwen2-7b-instruct\n",
      "qwen2-0.5b-instruct\n",
      "qwen-long\n",
      "qwen-vl-max\n",
      "qwen-vl-plus\n",
      "qwen-max-0428\n",
      "qwen1.5-110b-chat\n",
      "qwen-72b-chat\n",
      "qwen-7b-chat\n",
      "qwen-1.8b-chat\n",
      "qwen-1.8b-longcontext-chat\n",
      "qwen1.5-0.5b-chat\n",
      "codeqwen1.5-7b-chat\n",
      "qwen-14b-chat\n",
      "qwen1.5-1.8b-chat\n",
      "qwen1.5-32b-chat\n",
      "qwen1.5-72b-chat\n",
      "qwen-max-longcontext\n",
      "qwen-max-1201\n",
      "qwen1.5-14b-chat\n",
      "qwen-max\n",
      "qwen-max-0403\n",
      "qwen-max-0107\n",
      "qwen-turbo\n",
      "qwen-plus\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Modify OpenAI's API key and API base to use vLLM's API server.\n",
    "# openai_api_key = \"EMPTY\"\n",
    "# openai_api_base = \"http://localhost:8001/v1\"\n",
    "# openai_api_key = os.getenv(\"DASHSCOPE_API_KEY\") # not work in Jupyter\n",
    "openai_api_key = \"sk-96e8a9444a5e48ea9cbc83d94f647239\"\n",
    "openai_api_base = \"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "\n",
    "\n",
    "models = client.models.list()\n",
    "model_path = models.data[0].id\n",
    "print(f'model_path: {model_path}')\n",
    "\n",
    "# 查看API有哪些模型\n",
    "# for model in models.data:\n",
    "for model in models:\n",
    "    print(model.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(id='deepseek-v3', created=1740023101, object='model', owned_by='system'),\n",
       " Model(id='deepseek-r1-distill-llama-70b', created=1739966973, object='model', owned_by='system'),\n",
       " Model(id='deepseek-r1-distill-qwen-32b', created=1739966940, object='model', owned_by='system'),\n",
       " Model(id='deepseek-r1-distill-qwen-14b', created=1739966931, object='model', owned_by='system'),\n",
       " Model(id='deepseek-r1-distill-llama-8b', created=1739966898, object='model', owned_by='system'),\n",
       " Model(id='deepseek-r1-distill-qwen-1.5b', created=1739966882, object='model', owned_by='system'),\n",
       " Model(id='deepseek-r1-distill-qwen-7b', created=1739966868, object='model', owned_by='system'),\n",
       " Model(id='deepseek-r1', created=1739966853, object='model', owned_by='system'),\n",
       " Model(id='qwen1.5-7b-chat', created=1735036190, object='model', owned_by='system'),\n",
       " Model(id='qwen-vl-ocr-latest', created=1732693133, object='model', owned_by='system'),\n",
       " Model(id='qwen-vl-ocr', created=1732693123, object='model', owned_by='system'),\n",
       " Model(id='qwen-coder-plus-1106', created=1731253544, object='model', owned_by='system'),\n",
       " Model(id='qwen-coder-plus', created=1731253525, object='model', owned_by='system'),\n",
       " Model(id='qwen-coder-plus-latest', created=1731253510, object='model', owned_by='system'),\n",
       " Model(id='qwen2.5-coder-3b-instruct', created=1731253500, object='model', owned_by='system'),\n",
       " Model(id='qwen2.5-coder-0.5b-instruct', created=1731253490, object='model', owned_by='system'),\n",
       " Model(id='qwen2.5-coder-14b-instruct', created=1731253478, object='model', owned_by='system'),\n",
       " Model(id='qwen2.5-coder-32b-instruct', created=1731253464, object='model', owned_by='system'),\n",
       " Model(id='qwen-coder-turbo-0919', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen2.5-0.5b-instruct', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen2.5-1.5b-instruct', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen2.5-3b-instruct', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen2.5-7b-instruct', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen2.5-14b-instruct', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen2.5-32b-instruct', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen2.5-72b-instruct', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen2.5-coder-7b-instruct', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen2.5-math-1.5b-instruct', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen2.5-math-7b-instruct', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen2.5-math-72b-instruct', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen-turbo-0919', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen-turbo-latest', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen-plus-0919', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen-plus-latest', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen-max-0919', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen-max-latest', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen-coder-turbo', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen-coder-turbo-latest', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen-math-turbo-0919', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen-math-turbo', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen-math-turbo-latest', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen-math-plus-0919', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen-math-plus', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen-math-plus-latest', created=1726638000, object='model', owned_by='system'),\n",
       " Model(id='qwen2-1.5b-instruct', created=1717760433, object='model', owned_by='system'),\n",
       " Model(id='qwen2-57b-a14b-instruct', created=1717760433, object='model', owned_by='system'),\n",
       " Model(id='qwen2-72b-instruct', created=1717760433, object='model', owned_by='system'),\n",
       " Model(id='qwen2-7b-instruct', created=1717760433, object='model', owned_by='system'),\n",
       " Model(id='qwen2-0.5b-instruct', created=1717760433, object='model', owned_by='system'),\n",
       " Model(id='qwen-long', created=1716203538, object='model', owned_by='system'),\n",
       " Model(id='qwen-vl-max', created=1716197964, object='model', owned_by='system'),\n",
       " Model(id='qwen-vl-plus', created=1716197934, object='model', owned_by='system'),\n",
       " Model(id='qwen-max-0428', created=1714978712, object='model', owned_by='system'),\n",
       " Model(id='qwen1.5-110b-chat', created=1714788848, object='model', owned_by='system'),\n",
       " Model(id='qwen-72b-chat', created=1714377102, object='model', owned_by='system'),\n",
       " Model(id='qwen-7b-chat', created=1714377102, object='model', owned_by='system'),\n",
       " Model(id='qwen-1.8b-chat', created=1714377102, object='model', owned_by='system'),\n",
       " Model(id='qwen-1.8b-longcontext-chat', created=1714377102, object='model', owned_by='system'),\n",
       " Model(id='qwen1.5-0.5b-chat', created=1714377102, object='model', owned_by='system'),\n",
       " Model(id='codeqwen1.5-7b-chat', created=1714377102, object='model', owned_by='system'),\n",
       " Model(id='qwen-14b-chat', created=1714377102, object='model', owned_by='system'),\n",
       " Model(id='qwen1.5-1.8b-chat', created=1714377101, object='model', owned_by='system'),\n",
       " Model(id='qwen1.5-32b-chat', created=1714377101, object='model', owned_by='system'),\n",
       " Model(id='qwen1.5-72b-chat', created=1714377101, object='model', owned_by='system'),\n",
       " Model(id='qwen-max-longcontext', created=1714377101, object='model', owned_by='system'),\n",
       " Model(id='qwen-max-1201', created=1714377101, object='model', owned_by='system'),\n",
       " Model(id='qwen1.5-14b-chat', created=1714377101, object='model', owned_by='system'),\n",
       " Model(id='qwen-max', created=1714377100, object='model', owned_by='system'),\n",
       " Model(id='qwen-max-0403', created=1714377100, object='model', owned_by='system'),\n",
       " Model(id='qwen-max-0107', created=1714377100, object='model', owned_by='system'),\n",
       " Model(id='qwen-turbo', created=1714377100, object='model', owned_by='system'),\n",
       " Model(id='qwen-plus', created=1714377100, object='model', owned_by='system')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt tokens: 40\n",
      "Completion tokens: 725\n",
      "Total tokens: 765\n",
      "Output: 作为一个文本模型，我无法直接识别和框出图片中的动物。你需要使用图像识别技术，如深度学习模型，来进行这个任务。这些模型通常需要大量的标注数据来训练，以便准确地识别图片中的对象。\n",
      "\n",
      "然而，如果你已经有了这样的数据集，你可以使用这些数据集来训练模型，并使用这些模型来识别新的图片。一旦模型被训练，你就可以将图片输入到模型中，模型会输出一个或多个物体的边界框和预测的类别。\n",
      "\n",
      "以下是一个简单的例子，展示了如何使用Python的PIL库和OpenCV库来识别图像中的动物：\n",
      "\n",
      "```python\n",
      "import cv2\n",
      "import numpy as np\n",
      "import json\n",
      "\n",
      "def recognize_animal(image_path):\n",
      "    # 读取图片\n",
      "    image = cv2.imread(image_path)\n",
      "    \n",
      "    # 将图片转换为灰度\n",
      "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
      "    \n",
      "    # 应用高斯滤波以平滑图像\n",
      "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
      "    \n",
      "    # 将灰度图像转换为直方图\n",
      "    histogram = np.sum(gray, axis=0)\n",
      "    \n",
      "    # 找到最大值的索引\n",
      "    max_val = np.max(histogram)\n",
      "    maxInd = np.unravel_index(np.argmax(histogram, axis=None), histogram.shape)\n",
      "    \n",
      "    # 计算最大值对应的通道位置\n",
      "    maxInd = maxInd[1] * 3 + maxInd[0]\n",
      "    \n",
      "    # 将最大值对应的通道从直方图中提取出来\n",
      "    maxPixel = np.copy(histogram)\n",
      "    maxPixel[maxInd[0], maxInd[1]] = 0\n",
      "    \n",
      "    # 将直方图与最大值对应通道进行求和\n",
      "    sumPixel = np.sum(maxPixel, axis=0)\n",
      "    \n",
      "    # 计算阈值\n",
      "    THRESHOLD = 1500 / sumPixel.max()\n",
      "    \n",
      "    # 将灰度图像二值化\n",
      "    binary = cv2.threshold(gray, THRESHOLD, 255, cv2.THRESH_BINARY)[1]\n",
      "    \n",
      "    # 用模板匹配找到轮廓\n",
      "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
      "    contours = contours[0]\n",
      "    \n",
      "    # 遍历轮廓\n",
      "    for contour in contours:\n",
      "        # 计算轮廓的中心\n",
      "        x, y, w, h = cv2.boundingRect(contour)\n",
      "        \n",
      "        # 计算边界框\n",
      "        bbox = (x, y, x+w, y+h)\n",
      "        \n",
      "        # 计算轮廓的周长\n",
      "        perimeter = cv2.arcLength(contour, True)\n",
      "        \n",
      "        # 如果周长小于轮廓的宽度，那么轮廓是精确的，我们计算动物的边界框\n",
      "        if perimeter / 2.0 < w / 2.0:\n",
      "            # 计算动物的边界框\n",
      "            bbox = (int(x), int(y), int(x+w), int(y+h))\n",
      "            animal = \"Dog\"\n",
      "    \n",
      "    # 返回边界框和动物的类别\n",
      "    return bbox, animal\n",
      "\n",
      "bbox, animal = recognize_animal(\"image.jpg\")\n",
      "print(f\"Animal bbox: {bbox}\")\n",
      "print(f\"Animal: {animal}\")\n",
      "```\n",
      "\n",
      "请注意，这只是一个非常基础的示例，实际的图像识别可能需要更复杂的算法和大量的数据。\n"
     ]
    }
   ],
   "source": [
    "# model_path = \"qwen-vl-max\"\n",
    "# model_path = \"qwen-vl-max-0125\" # qwen2.5-vl\n",
    "# model_path = \"qwen-vl-max-1230\" \n",
    "# model_path = \"qwen-vl-chat-v1\" # 说是一个文本模型\n",
    "model_path = \"qwen-vl-v1\"\n",
    "\n",
    "# image_url_duck = \"https://upload.wikimedia.org/wikipedia/commons/d/da/2015_Kaczka_krzy%C5%BCowka_w_wodzie_%28samiec%29.jpg\"\n",
    "# image_url_lion = \"https://upload.wikimedia.org/wikipedia/commons/7/77/002_The_lion_king_Snyggve_in_the_Serengeti_National_Park_Photo_by_Giles_Laurent.jpg\"\n",
    "\n",
    "image_url_duck = \"https://q9.itc.cn/images01/20240529/091866645b3c485fb1a493ecbe302e06.png\"\n",
    "image_url_lion = \"https://pics4.baidu.com/feed/b999a9014c086e06cff1723bb02d58fb0ad1cb1e.jpeg\"\n",
    "\n",
    "messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant.\"}],\n",
    "        },\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\", \n",
    "                # \"text\": \"What are the animals in these images?\"\n",
    "                # \"text\": \"给图片中的动物打锚框，输出起bbox，用（x,y,x,y）的格式\"\n",
    "                \"text\": \"识别图片中是动物，将其框出以json格式返回起bbox坐标，并回答是什么动物。\"\n",
    "            },\n",
    "            # {\n",
    "            #     \"type\": \"image_url\",\n",
    "            #     \"image_url\": {\n",
    "            #         \"url\": image_url_duck\n",
    "            #         # \"url\": f\"data:image/png;base64,{a}\"\n",
    "            #     },\n",
    "            # },\n",
    "            # {\n",
    "            #     \"type\": \"image_url\",\n",
    "            #     \"image_url\": {\n",
    "            #         \"url\": image_url_lion\n",
    "            #         # \"url\": f\"data:image/png;base64,{a1}\"\n",
    "            #     },\n",
    "            # },\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=model_path,\n",
    "    max_completion_tokens=64,\n",
    "    messages=messages\n",
    "    \n",
    ")\n",
    "\n",
    "prompt_tokens = chat_completion.usage.prompt_tokens\n",
    "completion_tokens = chat_completion.usage.completion_tokens\n",
    "total_tokens = chat_completion.usage.total_tokens\n",
    "\n",
    "print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "print(f\"Completion tokens: {completion_tokens}\")\n",
    "print(f\"Total tokens: {total_tokens}\")\n",
    "\n",
    "\n",
    "assistant_message = chat_completion.choices[0].message\n",
    "messages.append(assistant_message.model_dump())\n",
    "\n",
    "response = chat_completion.choices[0].message.content\n",
    "print(\"Output:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n[\\n\\t{\"bbox_2d\": [14, 49, 620, 329], \"label\": \"鸭子\"}\\n]\\n```'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'The animal in the image is a male mallard duck. Mallards are easily recognizable by their distinctive plumage, with males having a glossy green head, a white ring around the neck, a yellow bill, and a mix of gray and brown on the body.',\n",
       " 'refusal': None,\n",
       " 'role': 'assistant',\n",
       " 'audio': None,\n",
       " 'function_call': None,\n",
       " 'tool_calls': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = assistant_message.model_dump()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"id\":\"chatcmpl-d60661c1-2216-9184-9383-214a68b146a8\",\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"logprobs\":null,\"message\":{\"content\":\"The animal in the image is a male mallard duck. Mallards are easily recognizable by their distinctive plumage, with males having a glossy green head, a white ring around the neck, a yellow bill, and a mix of gray and brown on the body.\",\"refusal\":null,\"role\":\"assistant\",\"audio\":null,\"function_call\":null,\"tool_calls\":null}}],\"created\":1739974851,\"model\":\"qwen-vl-max\",\"object\":\"chat.completion\",\"service_tier\":null,\"system_fingerprint\":null,\"usage\":{\"completion_tokens\":53,\"prompt_tokens\":429,\"total_tokens\":482,\"completion_tokens_details\":null,\"prompt_tokens_details\":null}}'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = chat_completion.model_dump_json()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.completions.create(model=model_path,\n",
    "                                      prompt=\"San Francisco is a\")\n",
    "print(\"Completion result:\\n\", completion.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response = client.chat.completions.create(\n",
    "    model=model_path,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a joke.\"},\n",
    "    ]\n",
    ")\n",
    "print(\"Chat response:\\n\", chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: /share_data/yanruilin/saves/qwen2_5vl-7b/full/sft/majiang_turn_1016_merge6/checkpoint-500\n",
      "Files: ['1546_0.png', '1547_0.png', '1548_0.png', '1549_0.png', '1550_0.png']\n",
      "Latency (huihe, 5 imgs): 298.39 ms\n",
      "Assistant: myself\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "import base64, mimetypes, time\n",
    "\n",
    "client = OpenAI(api_key=\"EMPTY\", base_url=\"http://127.0.0.1:8001/v1\")\n",
    "model_id = client.models.list().data[0].id\n",
    "print(\"Using model:\", model_id)\n",
    "\n",
    "# 从 z_multi_0905 选取连续5张图片，按文件名排序取前5张\n",
    "images_dir = Path(\"data/multi_test_origin\").resolve()\n",
    "seq = [images_dir / f\"{i}_0.png\" for i in range(1546,1551)]\n",
    "print(\"Files:\", [p.name for p in seq])\n",
    "\n",
    "# 转为 data URL 列表\n",
    "image_urls = []\n",
    "for p in seq:\n",
    "    mime, _ = mimetypes.guess_type(str(p))\n",
    "    if mime is None:\n",
    "        mime = \"application/octet-stream\"\n",
    "    with open(p, \"rb\") as f:\n",
    "        b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    image_urls.append(f\"data:{mime};base64,{b64}\")\n",
    "\n",
    "# 回合（多图）并测延时\n",
    "start = time.perf_counter()\n",
    "resp_huihe = client.chat.completions.create(\n",
    "    model=model_id,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\n",
    "                \"type\": \"text\",\n",
    "                \"text\": (\n",
    "                    \"You are a professional Mahjong AI assistant. You need to carefully analyze the Mahjong scene in the image—including the wall, the discard area, and the players' hand movements—and then precisely determine whose turn it is now. \"\n",
    "                    \"Your answer must be and can only be one of the following: myself, next, opposite, previous, or unknown. Do not output anything else.\"\n",
    "                )\n",
    "            }],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                [{\"type\": \"image_url\", \"image_url\": {\"url\": url}} for url in image_urls]\n",
    "                + [{\"type\": \"text\", \"text\": \"Whose turn is it now?\"}]\n",
    "            ),\n",
    "        },\n",
    "    ],\n",
    "    temperature=0.95,\n",
    "    max_tokens=128,\n",
    ")\n",
    "elapsed_ms = (time.perf_counter() - start) * 1000.0\n",
    "print(f\"Latency (huihe, 5 imgs): {elapsed_ms:.2f} ms\")\n",
    "print(\"Assistant:\", resp_huihe.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamafactory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
